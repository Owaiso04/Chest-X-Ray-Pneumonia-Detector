{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3256cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71faab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load & preprocess images\n",
    "def load_and_preprocess(image_paths, label, img_size=(224, 224)):\n",
    "    X, y = [], []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = preprocess_input(img.astype(\"float32\"))  # use ResNet preprocessor\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef379083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load & split training data\n",
    "norm_paths = glob.glob(\"./chest_xray/train/NORMAL/*.jpeg\")\n",
    "pneu_paths = glob.glob(\"./chest_xray/train/PNEUMONIA/*.jpeg\")\n",
    "\n",
    "X_norm, y_norm = load_and_preprocess(norm_paths, label=0)\n",
    "X_pneu, y_pneu = load_and_preprocess(pneu_paths, label=1)\n",
    "\n",
    "# Undersample PNEUMONIA to 2500\n",
    "X_pneu_under = X_pneu[:2500]\n",
    "y_pneu_under = y_pneu[:2500]\n",
    "\n",
    "# Train/validation split\n",
    "X_train_n, X_val_n, y_train_n, y_val_n = train_test_split(\n",
    "    X_norm, y_norm, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_p, X_val_p, y_train_p, y_val_p = train_test_split(\n",
    "    X_pneu_under, y_pneu_under, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Combine validation sets\n",
    "X_val = np.concatenate([X_val_n, X_val_p], axis=0)\n",
    "y_val = np.concatenate([y_val_n, y_val_p], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea6253fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generators (balanced)\n",
    "batch_size = 32\n",
    "half_bs = batch_size // 2\n",
    "\n",
    "aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "gen_norm = aug.flow(X_train_n, y_train_n, batch_size=half_bs, shuffle=True)\n",
    "gen_pneu = aug.flow(X_train_p, y_train_p, batch_size=half_bs, shuffle=True)\n",
    "\n",
    "\n",
    "def balanced_generator(gen0, gen1):\n",
    "    while True:\n",
    "        X0, y0 = next(gen0)\n",
    "        X1, y1 = next(gen1)\n",
    "        Xb = np.vstack([X0, X1])\n",
    "        yb = np.concatenate([y0, y1])\n",
    "        idx = np.random.permutation(len(yb))\n",
    "        yield Xb[idx], yb[idx]\n",
    "\n",
    "\n",
    "train_gen = balanced_generator(gen_norm, gen_pneu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3855c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build ResNet50 model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = ResNet50(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\"\n",
    ")\n",
    "base_model.trainable = False  # freeze for faster training\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8590 - auc: 0.9282 - loss: 0.3518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.8596 - auc: 0.9286 - loss: 0.3506 - val_accuracy: 0.9441 - val_auc: 0.9908 - val_loss: 0.1621\n",
      "Epoch 2/20\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.9360 - auc: 0.9774 - loss: 0.1826 - val_accuracy: 0.9337 - val_auc: 0.9932 - val_loss: 0.1929\n",
      "Epoch 3/20\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - accuracy: 0.9525 - auc: 0.9896 - loss: 0.1221 - val_accuracy: 0.9376 - val_auc: 0.9920 - val_loss: 0.1937\n",
      "Epoch 4/20\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.9486 - auc: 0.9863 - loss: 0.1432 - val_accuracy: 0.9051 - val_auc: 0.9952 - val_loss: 0.2453\n"
     ]
    }
   ],
   "source": [
    "# 5. Train\n",
    "steps_per_epoch = (len(X_train_n) + len(X_train_p)) // batch_size\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"resnet_model_3.h5\", save_best_only=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f6fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step\n",
      "Optimal sigmoid threshold = 0.523\n"
     ]
    }
   ],
   "source": [
    "val_probs = model.predict(X_val).ravel()\n",
    "\n",
    "# 6. Threshold tuning\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, val_probs)\n",
    "\n",
    "\n",
    "youden_j = tpr - fpr\n",
    "\n",
    "\n",
    "best_idx = np.argmax(youden_j)\n",
    "\n",
    "\n",
    "best_thresh = thresholds[best_idx]\n",
    "\n",
    "\n",
    "print(f\"Optimal sigmoid threshold = {best_thresh:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c74a6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Test data\n",
    "test_n = glob.glob(\"./chest_xray/test/NORMAL/*.jpeg\")\n",
    "test_p = glob.glob(\"./chest_xray/test/PNEUMONIA/*.jpeg\")\n",
    "X_test_n, y_test_n = load_and_preprocess(test_n, label=0)\n",
    "X_test_p, y_test_p = load_and_preprocess(test_p, label=1)\n",
    "\n",
    "X_test = np.concatenate([X_test_n, X_test_p], axis=0)\n",
    "y_test = np.concatenate([y_test_n, y_test_p], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a40aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate using tuned threshold\n",
    "test_probs = model.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2edd2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (test_probs >= best_thresh).astype(int)  # best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe4210e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3065, Acc: 0.8766, AUC: 0.9434\n"
     ]
    }
   ],
   "source": [
    "loss, acc, auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Acc: {acc:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69afd84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.81      0.83       234\n",
      "   Pneumonia       0.89      0.92      0.91       390\n",
      "\n",
      "    accuracy                           0.88       624\n",
      "   macro avg       0.88      0.87      0.87       624\n",
      "weighted avg       0.88      0.88      0.88       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Normal\", \"Pneumonia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                  Normal (pred)  Pneumonia (pred)\n",
      "Normal (true)               189                45\n",
      "Pneumonia (true)             30               360\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "# Display with readable labels\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Normal (true)\", \"Pneumonia (true)\"],\n",
    "    columns=[\"Normal (pred)\", \"Pneumonia (pred)\"],\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7606d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.8798076923076923\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
